{"cells":[{"cell_type":"markdown","metadata":{"id":"Gldcjn8lTYip"},"source":["___\n","\n","<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n","___\n","\n","# Keras Basics\n","\n","Welcome to the section on deep learning! We'll be using Keras with a TensorFlow backend to perform our deep learning operations.\n","\n","This means we should get familiar with some Keras fundamentals and basics!\n","\n","## Imports\n","\n"]},{"cell_type":"markdown","source":["꽃잎과 꽃받침 측정 값과 세가지 클래스 중 하나에 상응하는 레이블 포함"],"metadata":{"id":"uOeRrB8lT-8i"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lY-xqpu4TYir"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"iAaQjDy7TYis"},"source":["## Dataset\n","\n","We will use the famous Iris Data set.\n","_____\n","More info on the data set:\n","https://en.wikipedia.org/wiki/Iris_flower_data_set\n","\n","## Reading in the Data Set\n","\n","We've already downloaded the dataset, its in this folder. So let's open it up."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vp7sSc7tTYis"},"outputs":[],"source":["from sklearn.datasets import load_iris #scikit-learn 라이브러리에서 load_iris 함수를 불러오는 것\n","# Iris 데이터셋은 붓꽃의 꽃잎과 꽃받침의 길이와 너비를 측정한 데이터\n","# 세 가지 붓꽃 종(species)인 'setosa', 'versicolor', 'virginica'를 분류하기 위한 기능(feature)을 제공\n","#머신러닝과 패턴인식 연구에서 많이 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Khm4C2cTYit"},"outputs":[],"source":["iris = load_iris() # Iris 데이터셋을 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_x5aw-cTYit","executionInfo":{"status":"ok","timestamp":1707898221187,"user_tz":-540,"elapsed":34,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"aa8d45d9-544a-4f0b-cdb3-68222618bda1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["sklearn.utils._bunch.Bunch"]},"metadata":{},"execution_count":158}],"source":["type(iris)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmKlR_3XTYit","executionInfo":{"status":"ok","timestamp":1707898221187,"user_tz":-540,"elapsed":34,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"928637b9-9d82-4969-cb93-0b87cc0ee232"},"outputs":[{"output_type":"stream","name":"stdout","text":[".. _iris_dataset:\n","\n","Iris plants dataset\n","--------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 150 (50 in each of three classes)\n","    :Number of Attributes: 4 numeric, predictive attributes and the class\n","    :Attribute Information:\n","        - sepal length in cm\n","        - sepal width in cm\n","        - petal length in cm\n","        - petal width in cm\n","        - class:\n","                - Iris-Setosa\n","                - Iris-Versicolour\n","                - Iris-Virginica\n","                \n","    :Summary Statistics:\n","\n","    ============== ==== ==== ======= ===== ====================\n","                    Min  Max   Mean    SD   Class Correlation\n","    ============== ==== ==== ======= ===== ====================\n","    sepal length:   4.3  7.9   5.84   0.83    0.7826\n","    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n","    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n","    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n","    ============== ==== ==== ======= ===== ====================\n","\n","    :Missing Attribute Values: None\n","    :Class Distribution: 33.3% for each of 3 classes.\n","    :Creator: R.A. Fisher\n","    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n","    :Date: July, 1988\n","\n","The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n","from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n","Machine Learning Repository, which has two wrong data points.\n","\n","This is perhaps the best known database to be found in the\n","pattern recognition literature.  Fisher's paper is a classic in the field and\n","is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n","data set contains 3 classes of 50 instances each, where each class refers to a\n","type of iris plant.  One class is linearly separable from the other 2; the\n","latter are NOT linearly separable from each other.\n","\n",".. topic:: References\n","\n","   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n","     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n","     Mathematical Statistics\" (John Wiley, NY, 1950).\n","   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n","     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n","   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n","     Structure and Classification Rule for Recognition in Partially Exposed\n","     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n","     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n","   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n","     on Information Theory, May 1972, 431-433.\n","   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n","     conceptual clustering system finds 3 classes in the data.\n","   - Many, many more ...\n"]}],"source":["print(iris.DESCR) #설명, 속성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2K-yF2aQTYit"},"outputs":[],"source":["X = iris.data # Iris 데이터셋의 특징 데이터가 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCSrJL8KTYiu","executionInfo":{"status":"ok","timestamp":1707898221187,"user_tz":-540,"elapsed":32,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"390635a3-1e76-46f6-a004-5dff9ecd683e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5.1, 3.5, 1.4, 0.2],\n","       [4.9, 3. , 1.4, 0.2],\n","       [4.7, 3.2, 1.3, 0.2],\n","       [4.6, 3.1, 1.5, 0.2],\n","       [5. , 3.6, 1.4, 0.2],\n","       [5.4, 3.9, 1.7, 0.4],\n","       [4.6, 3.4, 1.4, 0.3],\n","       [5. , 3.4, 1.5, 0.2],\n","       [4.4, 2.9, 1.4, 0.2],\n","       [4.9, 3.1, 1.5, 0.1],\n","       [5.4, 3.7, 1.5, 0.2],\n","       [4.8, 3.4, 1.6, 0.2],\n","       [4.8, 3. , 1.4, 0.1],\n","       [4.3, 3. , 1.1, 0.1],\n","       [5.8, 4. , 1.2, 0.2],\n","       [5.7, 4.4, 1.5, 0.4],\n","       [5.4, 3.9, 1.3, 0.4],\n","       [5.1, 3.5, 1.4, 0.3],\n","       [5.7, 3.8, 1.7, 0.3],\n","       [5.1, 3.8, 1.5, 0.3],\n","       [5.4, 3.4, 1.7, 0.2],\n","       [5.1, 3.7, 1.5, 0.4],\n","       [4.6, 3.6, 1. , 0.2],\n","       [5.1, 3.3, 1.7, 0.5],\n","       [4.8, 3.4, 1.9, 0.2],\n","       [5. , 3. , 1.6, 0.2],\n","       [5. , 3.4, 1.6, 0.4],\n","       [5.2, 3.5, 1.5, 0.2],\n","       [5.2, 3.4, 1.4, 0.2],\n","       [4.7, 3.2, 1.6, 0.2],\n","       [4.8, 3.1, 1.6, 0.2],\n","       [5.4, 3.4, 1.5, 0.4],\n","       [5.2, 4.1, 1.5, 0.1],\n","       [5.5, 4.2, 1.4, 0.2],\n","       [4.9, 3.1, 1.5, 0.2],\n","       [5. , 3.2, 1.2, 0.2],\n","       [5.5, 3.5, 1.3, 0.2],\n","       [4.9, 3.6, 1.4, 0.1],\n","       [4.4, 3. , 1.3, 0.2],\n","       [5.1, 3.4, 1.5, 0.2],\n","       [5. , 3.5, 1.3, 0.3],\n","       [4.5, 2.3, 1.3, 0.3],\n","       [4.4, 3.2, 1.3, 0.2],\n","       [5. , 3.5, 1.6, 0.6],\n","       [5.1, 3.8, 1.9, 0.4],\n","       [4.8, 3. , 1.4, 0.3],\n","       [5.1, 3.8, 1.6, 0.2],\n","       [4.6, 3.2, 1.4, 0.2],\n","       [5.3, 3.7, 1.5, 0.2],\n","       [5. , 3.3, 1.4, 0.2],\n","       [7. , 3.2, 4.7, 1.4],\n","       [6.4, 3.2, 4.5, 1.5],\n","       [6.9, 3.1, 4.9, 1.5],\n","       [5.5, 2.3, 4. , 1.3],\n","       [6.5, 2.8, 4.6, 1.5],\n","       [5.7, 2.8, 4.5, 1.3],\n","       [6.3, 3.3, 4.7, 1.6],\n","       [4.9, 2.4, 3.3, 1. ],\n","       [6.6, 2.9, 4.6, 1.3],\n","       [5.2, 2.7, 3.9, 1.4],\n","       [5. , 2. , 3.5, 1. ],\n","       [5.9, 3. , 4.2, 1.5],\n","       [6. , 2.2, 4. , 1. ],\n","       [6.1, 2.9, 4.7, 1.4],\n","       [5.6, 2.9, 3.6, 1.3],\n","       [6.7, 3.1, 4.4, 1.4],\n","       [5.6, 3. , 4.5, 1.5],\n","       [5.8, 2.7, 4.1, 1. ],\n","       [6.2, 2.2, 4.5, 1.5],\n","       [5.6, 2.5, 3.9, 1.1],\n","       [5.9, 3.2, 4.8, 1.8],\n","       [6.1, 2.8, 4. , 1.3],\n","       [6.3, 2.5, 4.9, 1.5],\n","       [6.1, 2.8, 4.7, 1.2],\n","       [6.4, 2.9, 4.3, 1.3],\n","       [6.6, 3. , 4.4, 1.4],\n","       [6.8, 2.8, 4.8, 1.4],\n","       [6.7, 3. , 5. , 1.7],\n","       [6. , 2.9, 4.5, 1.5],\n","       [5.7, 2.6, 3.5, 1. ],\n","       [5.5, 2.4, 3.8, 1.1],\n","       [5.5, 2.4, 3.7, 1. ],\n","       [5.8, 2.7, 3.9, 1.2],\n","       [6. , 2.7, 5.1, 1.6],\n","       [5.4, 3. , 4.5, 1.5],\n","       [6. , 3.4, 4.5, 1.6],\n","       [6.7, 3.1, 4.7, 1.5],\n","       [6.3, 2.3, 4.4, 1.3],\n","       [5.6, 3. , 4.1, 1.3],\n","       [5.5, 2.5, 4. , 1.3],\n","       [5.5, 2.6, 4.4, 1.2],\n","       [6.1, 3. , 4.6, 1.4],\n","       [5.8, 2.6, 4. , 1.2],\n","       [5. , 2.3, 3.3, 1. ],\n","       [5.6, 2.7, 4.2, 1.3],\n","       [5.7, 3. , 4.2, 1.2],\n","       [5.7, 2.9, 4.2, 1.3],\n","       [6.2, 2.9, 4.3, 1.3],\n","       [5.1, 2.5, 3. , 1.1],\n","       [5.7, 2.8, 4.1, 1.3],\n","       [6.3, 3.3, 6. , 2.5],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [7.1, 3. , 5.9, 2.1],\n","       [6.3, 2.9, 5.6, 1.8],\n","       [6.5, 3. , 5.8, 2.2],\n","       [7.6, 3. , 6.6, 2.1],\n","       [4.9, 2.5, 4.5, 1.7],\n","       [7.3, 2.9, 6.3, 1.8],\n","       [6.7, 2.5, 5.8, 1.8],\n","       [7.2, 3.6, 6.1, 2.5],\n","       [6.5, 3.2, 5.1, 2. ],\n","       [6.4, 2.7, 5.3, 1.9],\n","       [6.8, 3. , 5.5, 2.1],\n","       [5.7, 2.5, 5. , 2. ],\n","       [5.8, 2.8, 5.1, 2.4],\n","       [6.4, 3.2, 5.3, 2.3],\n","       [6.5, 3. , 5.5, 1.8],\n","       [7.7, 3.8, 6.7, 2.2],\n","       [7.7, 2.6, 6.9, 2.3],\n","       [6. , 2.2, 5. , 1.5],\n","       [6.9, 3.2, 5.7, 2.3],\n","       [5.6, 2.8, 4.9, 2. ],\n","       [7.7, 2.8, 6.7, 2. ],\n","       [6.3, 2.7, 4.9, 1.8],\n","       [6.7, 3.3, 5.7, 2.1],\n","       [7.2, 3.2, 6. , 1.8],\n","       [6.2, 2.8, 4.8, 1.8],\n","       [6.1, 3. , 4.9, 1.8],\n","       [6.4, 2.8, 5.6, 2.1],\n","       [7.2, 3. , 5.8, 1.6],\n","       [7.4, 2.8, 6.1, 1.9],\n","       [7.9, 3.8, 6.4, 2. ],\n","       [6.4, 2.8, 5.6, 2.2],\n","       [6.3, 2.8, 5.1, 1.5],\n","       [6.1, 2.6, 5.6, 1.4],\n","       [7.7, 3. , 6.1, 2.3],\n","       [6.3, 3.4, 5.6, 2.4],\n","       [6.4, 3.1, 5.5, 1.8],\n","       [6. , 3. , 4.8, 1.8],\n","       [6.9, 3.1, 5.4, 2.1],\n","       [6.7, 3.1, 5.6, 2.4],\n","       [6.9, 3.1, 5.1, 2.3],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [6.8, 3.2, 5.9, 2.3],\n","       [6.7, 3.3, 5.7, 2.5],\n","       [6.7, 3. , 5.2, 2.3],\n","       [6.3, 2.5, 5. , 1.9],\n","       [6.5, 3. , 5.2, 2. ],\n","       [6.2, 3.4, 5.4, 2.3],\n","       [5.9, 3. , 5.1, 1.8]])"]},"metadata":{},"execution_count":161}],"source":["X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwLEg2_RTYiu"},"outputs":[],"source":["y = iris.target # 해당 특징 데이터에 대응하는 분류 클래스가 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8tOXltxTYiu","executionInfo":{"status":"ok","timestamp":1707898221187,"user_tz":-540,"elapsed":29,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"93fd1203-81f1-47eb-d972-83d524d204aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"]},"metadata":{},"execution_count":163}],"source":["y"]},{"cell_type":"code","source":["#class 0 --> [1,0,0]\n","#class 1 --> [0,1,0]\n","#class 2 --> [1,0,1]\n","#원핫인코딩"],"metadata":{"id":"2jmvuJWDUxSD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZZps59ITYiu"},"outputs":[],"source":["from keras.utils import to_categorical #to_categorical 함수는 분류 문제에서 레이블을 원-핫 인코딩(one-hot encoding) 형식으로 변환하는 데 사용\n","#예를 들어, 클래스가 3개인 경우:\n","#클래스 0은 [1, 0, 0]\n","#클래스 1은 [0, 1, 0]\n","#클래스 2는 [0, 0, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"aY_lzU5sTYiu"},"outputs":[],"source":["y = to_categorical(y)\n","#이전의 레이블 형태:\n","\n","#클래스 0: 0\n","#클래스 1: 1\n","#클래스 2: 2\n","\n","#새로운 원-핫 인코딩된 레이블 형태:\n","\n","#클래스 0: [1, 0, 0]\n","#클래스 1: [0, 1, 0]\n","#클래스 2: [0, 0, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Di-SrlJCTYiu","executionInfo":{"status":"ok","timestamp":1707898221188,"user_tz":-540,"elapsed":26,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"766880c2-6076-4053-ff19-ee2ceff866fd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150, 3)"]},"metadata":{},"execution_count":167}],"source":["y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqPRrhvVTYiv","executionInfo":{"status":"ok","timestamp":1707898221188,"user_tz":-540,"elapsed":24,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"1ddbb1a1-26d6-4818-da62-12b1878a008c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.]], dtype=float32)"]},"metadata":{},"execution_count":168}],"source":["y #원핫 인코딩"]},{"cell_type":"markdown","metadata":{"id":"xs5ZRJXNTYiv"},"source":["## Split the Data into Training and Test\n","\n","Its time to split the data into a train/test set. Keep in mind, sometimes people like to split 3 ways, train/test/validation. We'll keep things simple for now. **Remember to check out the video explanation as to why we split and what all the parameters mean!**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"s6hCKvGjTYiv"},"outputs":[],"source":["from sklearn.model_selection import train_test_split #데이터셋을 학습용과 테스트용으로 나누는 데 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"LVcIP_T-TYiv"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","#random_state=42: 데이터를 무작위로 분할할 때 사용되는 난수 발생기의 시드(seed) 값입니다. 이 값을 설정하면 실행할 때마다 동일한 분할이 생성되므로 결과를 재현할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFCwFcAtTYiv","executionInfo":{"status":"ok","timestamp":1707898221188,"user_tz":-540,"elapsed":23,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"85f9e2b2-9fd4-415c-bbea-0309a99206f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5.7, 2.9, 4.2, 1.3],\n","       [7.6, 3. , 6.6, 2.1],\n","       [5.6, 3. , 4.5, 1.5],\n","       [5.1, 3.5, 1.4, 0.2],\n","       [7.7, 2.8, 6.7, 2. ],\n","       [5.8, 2.7, 4.1, 1. ],\n","       [5.2, 3.4, 1.4, 0.2],\n","       [5. , 3.5, 1.3, 0.3],\n","       [5.1, 3.8, 1.9, 0.4],\n","       [5. , 2. , 3.5, 1. ],\n","       [6.3, 2.7, 4.9, 1.8],\n","       [4.8, 3.4, 1.9, 0.2],\n","       [5. , 3. , 1.6, 0.2],\n","       [5.1, 3.3, 1.7, 0.5],\n","       [5.6, 2.7, 4.2, 1.3],\n","       [5.1, 3.4, 1.5, 0.2],\n","       [5.7, 3. , 4.2, 1.2],\n","       [7.7, 3.8, 6.7, 2.2],\n","       [4.6, 3.2, 1.4, 0.2],\n","       [6.2, 2.9, 4.3, 1.3],\n","       [5.7, 2.5, 5. , 2. ],\n","       [5.5, 4.2, 1.4, 0.2],\n","       [6. , 3. , 4.8, 1.8],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [6. , 2.2, 4. , 1. ],\n","       [5.4, 3. , 4.5, 1.5],\n","       [6.2, 3.4, 5.4, 2.3],\n","       [5.5, 2.3, 4. , 1.3],\n","       [5.4, 3.9, 1.7, 0.4],\n","       [5. , 2.3, 3.3, 1. ],\n","       [6.4, 2.7, 5.3, 1.9],\n","       [5. , 3.3, 1.4, 0.2],\n","       [5. , 3.2, 1.2, 0.2],\n","       [5.5, 2.4, 3.8, 1.1],\n","       [6.7, 3. , 5. , 1.7],\n","       [4.9, 3.1, 1.5, 0.2],\n","       [5.8, 2.8, 5.1, 2.4],\n","       [5. , 3.4, 1.5, 0.2],\n","       [5. , 3.5, 1.6, 0.6],\n","       [5.9, 3.2, 4.8, 1.8],\n","       [5.1, 2.5, 3. , 1.1],\n","       [6.9, 3.2, 5.7, 2.3],\n","       [6. , 2.7, 5.1, 1.6],\n","       [6.1, 2.6, 5.6, 1.4],\n","       [7.7, 3. , 6.1, 2.3],\n","       [5.5, 2.5, 4. , 1.3],\n","       [4.4, 2.9, 1.4, 0.2],\n","       [4.3, 3. , 1.1, 0.1],\n","       [6. , 2.2, 5. , 1.5],\n","       [7.2, 3.2, 6. , 1.8],\n","       [4.6, 3.1, 1.5, 0.2],\n","       [5.1, 3.5, 1.4, 0.3],\n","       [4.4, 3. , 1.3, 0.2],\n","       [6.3, 2.5, 4.9, 1.5],\n","       [6.3, 3.4, 5.6, 2.4],\n","       [4.6, 3.4, 1.4, 0.3],\n","       [6.8, 3. , 5.5, 2.1],\n","       [6.3, 3.3, 6. , 2.5],\n","       [4.7, 3.2, 1.3, 0.2],\n","       [6.1, 2.9, 4.7, 1.4],\n","       [6.5, 2.8, 4.6, 1.5],\n","       [6.2, 2.8, 4.8, 1.8],\n","       [7. , 3.2, 4.7, 1.4],\n","       [6.4, 3.2, 5.3, 2.3],\n","       [5.1, 3.8, 1.6, 0.2],\n","       [6.9, 3.1, 5.4, 2.1],\n","       [5.9, 3. , 4.2, 1.5],\n","       [6.5, 3. , 5.2, 2. ],\n","       [5.7, 2.6, 3.5, 1. ],\n","       [5.2, 2.7, 3.9, 1.4],\n","       [6.1, 3. , 4.6, 1.4],\n","       [4.5, 2.3, 1.3, 0.3],\n","       [6.6, 2.9, 4.6, 1.3],\n","       [5.5, 2.6, 4.4, 1.2],\n","       [5.3, 3.7, 1.5, 0.2],\n","       [5.6, 3. , 4.1, 1.3],\n","       [7.3, 2.9, 6.3, 1.8],\n","       [6.7, 3.3, 5.7, 2.1],\n","       [5.1, 3.7, 1.5, 0.4],\n","       [4.9, 2.4, 3.3, 1. ],\n","       [6.7, 3.3, 5.7, 2.5],\n","       [7.2, 3. , 5.8, 1.6],\n","       [4.9, 3.6, 1.4, 0.1],\n","       [6.7, 3.1, 5.6, 2.4],\n","       [4.9, 3. , 1.4, 0.2],\n","       [6.9, 3.1, 4.9, 1.5],\n","       [7.4, 2.8, 6.1, 1.9],\n","       [6.3, 2.9, 5.6, 1.8],\n","       [5.7, 2.8, 4.1, 1.3],\n","       [6.5, 3. , 5.5, 1.8],\n","       [6.3, 2.3, 4.4, 1.3],\n","       [6.4, 2.9, 4.3, 1.3],\n","       [5.6, 2.8, 4.9, 2. ],\n","       [5.9, 3. , 5.1, 1.8],\n","       [5.4, 3.4, 1.7, 0.2],\n","       [6.1, 2.8, 4. , 1.3],\n","       [4.9, 2.5, 4.5, 1.7],\n","       [5.8, 4. , 1.2, 0.2],\n","       [5.8, 2.6, 4. , 1.2],\n","       [7.1, 3. , 5.9, 2.1]])"]},"metadata":{},"execution_count":171}],"source":["X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EVGXSVIeTYiv","executionInfo":{"status":"ok","timestamp":1707898221189,"user_tz":-540,"elapsed":22,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"3f4eb479-4fb2-4696-a4dd-c506ba5be1f8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6.1, 2.8, 4.7, 1.2],\n","       [5.7, 3.8, 1.7, 0.3],\n","       [7.7, 2.6, 6.9, 2.3],\n","       [6. , 2.9, 4.5, 1.5],\n","       [6.8, 2.8, 4.8, 1.4],\n","       [5.4, 3.4, 1.5, 0.4],\n","       [5.6, 2.9, 3.6, 1.3],\n","       [6.9, 3.1, 5.1, 2.3],\n","       [6.2, 2.2, 4.5, 1.5],\n","       [5.8, 2.7, 3.9, 1.2],\n","       [6.5, 3.2, 5.1, 2. ],\n","       [4.8, 3. , 1.4, 0.1],\n","       [5.5, 3.5, 1.3, 0.2],\n","       [4.9, 3.1, 1.5, 0.1],\n","       [5.1, 3.8, 1.5, 0.3],\n","       [6.3, 3.3, 4.7, 1.6],\n","       [6.5, 3. , 5.8, 2.2],\n","       [5.6, 2.5, 3.9, 1.1],\n","       [5.7, 2.8, 4.5, 1.3],\n","       [6.4, 2.8, 5.6, 2.2],\n","       [4.7, 3.2, 1.6, 0.2],\n","       [6.1, 3. , 4.9, 1.8],\n","       [5. , 3.4, 1.6, 0.4],\n","       [6.4, 2.8, 5.6, 2.1],\n","       [7.9, 3.8, 6.4, 2. ],\n","       [6.7, 3. , 5.2, 2.3],\n","       [6.7, 2.5, 5.8, 1.8],\n","       [6.8, 3.2, 5.9, 2.3],\n","       [4.8, 3. , 1.4, 0.3],\n","       [4.8, 3.1, 1.6, 0.2],\n","       [4.6, 3.6, 1. , 0.2],\n","       [5.7, 4.4, 1.5, 0.4],\n","       [6.7, 3.1, 4.4, 1.4],\n","       [4.8, 3.4, 1.6, 0.2],\n","       [4.4, 3.2, 1.3, 0.2],\n","       [6.3, 2.5, 5. , 1.9],\n","       [6.4, 3.2, 4.5, 1.5],\n","       [5.2, 3.5, 1.5, 0.2],\n","       [5. , 3.6, 1.4, 0.2],\n","       [5.2, 4.1, 1.5, 0.1],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [6. , 3.4, 4.5, 1.6],\n","       [6.7, 3.1, 4.7, 1.5],\n","       [5.4, 3.9, 1.3, 0.4],\n","       [5.4, 3.7, 1.5, 0.2],\n","       [5.5, 2.4, 3.7, 1. ],\n","       [6.3, 2.8, 5.1, 1.5],\n","       [6.4, 3.1, 5.5, 1.8],\n","       [6.6, 3. , 4.4, 1.4],\n","       [7.2, 3.6, 6.1, 2.5]])"]},"metadata":{},"execution_count":172}],"source":["X_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d50ioZu-TYiv","executionInfo":{"status":"ok","timestamp":1707898221189,"user_tz":-540,"elapsed":20,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"f8f0606d-4ba2-4acd-d897-172a439a2605"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.]], dtype=float32)"]},"metadata":{},"execution_count":173}],"source":["y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07kq6r8ETYiv","executionInfo":{"status":"ok","timestamp":1707898221189,"user_tz":-540,"elapsed":18,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"e64be53d-f71b-46bc-f419-63eefaf6f4aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.]], dtype=float32)"]},"metadata":{},"execution_count":174}],"source":["y_test"]},{"cell_type":"markdown","metadata":{"id":"f-nudOWNTYiv"},"source":["## Standardizing the Data\n","\n","Usually when using Neural Networks, you will get better performance when you standardize the data. Standardization just means normalizing the values to all fit between a certain range, like 0-1, or -1 to 1.\n","\n","The scikit learn library also provides a nice function for this.\n","\n","http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"iQ7m7VwjTYiw"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler #모든 것을 0과 1사이의 값으로 만드는 것\n","#MinMaxScaler는 주어진 범위 (일반적으로 0과 1 사이) 내에서 각 특징을 스케일링합니다.\n","#이렇게 하면 데이터의 분포가 원하는 범위로 조정되어 모델의 성능을 향상시키거나 최적화 알고리즘이 더 잘 수렴되도록 할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"ULX4DutzTYiw"},"outputs":[],"source":["scaler_object = MinMaxScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"0ODckKn-TYiw","executionInfo":{"status":"ok","timestamp":1707898221189,"user_tz":-540,"elapsed":16,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"721abb6c-7571-407a-bc4e-0ab9a2c8b412"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MinMaxScaler()"],"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":177}],"source":["scaler_object.fit(X_train) #X_train에 대해 스케일링을 적용하기 위해 모델을 피팅(fitting)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"zklL6gbhTYiw"},"outputs":[],"source":["scaled_X_train = scaler_object.transform(X_train) #transform 메서드는 주어진 데이터에 대해 스케일링을 적용하는 메서드"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"iZTUNIqxTYiw"},"outputs":[],"source":["scaled_X_test = scaler_object.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"Vi70Sz_oTYiw"},"source":["Ok, now we have the data scaled!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njl_ib86TYiw","executionInfo":{"status":"ok","timestamp":1707898221190,"user_tz":-540,"elapsed":16,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"b60ab83c-0662-4df5-e682-d3ace2edcaf2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["7.7"]},"metadata":{},"execution_count":180}],"source":["X_train.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLm9qoF4TYiw","executionInfo":{"status":"ok","timestamp":1707898221190,"user_tz":-540,"elapsed":14,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"7f7fe1e2-c29e-4fc7-d449-fd96ed4e259e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":181}],"source":["scaled_X_train.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RhCwKwi6TYiw","executionInfo":{"status":"ok","timestamp":1707898221190,"user_tz":-540,"elapsed":13,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"b4e57e37-9c83-4ac8-a3c5-d6b6e021a112"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5.7, 2.9, 4.2, 1.3],\n","       [7.6, 3. , 6.6, 2.1],\n","       [5.6, 3. , 4.5, 1.5],\n","       [5.1, 3.5, 1.4, 0.2],\n","       [7.7, 2.8, 6.7, 2. ],\n","       [5.8, 2.7, 4.1, 1. ],\n","       [5.2, 3.4, 1.4, 0.2],\n","       [5. , 3.5, 1.3, 0.3],\n","       [5.1, 3.8, 1.9, 0.4],\n","       [5. , 2. , 3.5, 1. ],\n","       [6.3, 2.7, 4.9, 1.8],\n","       [4.8, 3.4, 1.9, 0.2],\n","       [5. , 3. , 1.6, 0.2],\n","       [5.1, 3.3, 1.7, 0.5],\n","       [5.6, 2.7, 4.2, 1.3],\n","       [5.1, 3.4, 1.5, 0.2],\n","       [5.7, 3. , 4.2, 1.2],\n","       [7.7, 3.8, 6.7, 2.2],\n","       [4.6, 3.2, 1.4, 0.2],\n","       [6.2, 2.9, 4.3, 1.3],\n","       [5.7, 2.5, 5. , 2. ],\n","       [5.5, 4.2, 1.4, 0.2],\n","       [6. , 3. , 4.8, 1.8],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [6. , 2.2, 4. , 1. ],\n","       [5.4, 3. , 4.5, 1.5],\n","       [6.2, 3.4, 5.4, 2.3],\n","       [5.5, 2.3, 4. , 1.3],\n","       [5.4, 3.9, 1.7, 0.4],\n","       [5. , 2.3, 3.3, 1. ],\n","       [6.4, 2.7, 5.3, 1.9],\n","       [5. , 3.3, 1.4, 0.2],\n","       [5. , 3.2, 1.2, 0.2],\n","       [5.5, 2.4, 3.8, 1.1],\n","       [6.7, 3. , 5. , 1.7],\n","       [4.9, 3.1, 1.5, 0.2],\n","       [5.8, 2.8, 5.1, 2.4],\n","       [5. , 3.4, 1.5, 0.2],\n","       [5. , 3.5, 1.6, 0.6],\n","       [5.9, 3.2, 4.8, 1.8],\n","       [5.1, 2.5, 3. , 1.1],\n","       [6.9, 3.2, 5.7, 2.3],\n","       [6. , 2.7, 5.1, 1.6],\n","       [6.1, 2.6, 5.6, 1.4],\n","       [7.7, 3. , 6.1, 2.3],\n","       [5.5, 2.5, 4. , 1.3],\n","       [4.4, 2.9, 1.4, 0.2],\n","       [4.3, 3. , 1.1, 0.1],\n","       [6. , 2.2, 5. , 1.5],\n","       [7.2, 3.2, 6. , 1.8],\n","       [4.6, 3.1, 1.5, 0.2],\n","       [5.1, 3.5, 1.4, 0.3],\n","       [4.4, 3. , 1.3, 0.2],\n","       [6.3, 2.5, 4.9, 1.5],\n","       [6.3, 3.4, 5.6, 2.4],\n","       [4.6, 3.4, 1.4, 0.3],\n","       [6.8, 3. , 5.5, 2.1],\n","       [6.3, 3.3, 6. , 2.5],\n","       [4.7, 3.2, 1.3, 0.2],\n","       [6.1, 2.9, 4.7, 1.4],\n","       [6.5, 2.8, 4.6, 1.5],\n","       [6.2, 2.8, 4.8, 1.8],\n","       [7. , 3.2, 4.7, 1.4],\n","       [6.4, 3.2, 5.3, 2.3],\n","       [5.1, 3.8, 1.6, 0.2],\n","       [6.9, 3.1, 5.4, 2.1],\n","       [5.9, 3. , 4.2, 1.5],\n","       [6.5, 3. , 5.2, 2. ],\n","       [5.7, 2.6, 3.5, 1. ],\n","       [5.2, 2.7, 3.9, 1.4],\n","       [6.1, 3. , 4.6, 1.4],\n","       [4.5, 2.3, 1.3, 0.3],\n","       [6.6, 2.9, 4.6, 1.3],\n","       [5.5, 2.6, 4.4, 1.2],\n","       [5.3, 3.7, 1.5, 0.2],\n","       [5.6, 3. , 4.1, 1.3],\n","       [7.3, 2.9, 6.3, 1.8],\n","       [6.7, 3.3, 5.7, 2.1],\n","       [5.1, 3.7, 1.5, 0.4],\n","       [4.9, 2.4, 3.3, 1. ],\n","       [6.7, 3.3, 5.7, 2.5],\n","       [7.2, 3. , 5.8, 1.6],\n","       [4.9, 3.6, 1.4, 0.1],\n","       [6.7, 3.1, 5.6, 2.4],\n","       [4.9, 3. , 1.4, 0.2],\n","       [6.9, 3.1, 4.9, 1.5],\n","       [7.4, 2.8, 6.1, 1.9],\n","       [6.3, 2.9, 5.6, 1.8],\n","       [5.7, 2.8, 4.1, 1.3],\n","       [6.5, 3. , 5.5, 1.8],\n","       [6.3, 2.3, 4.4, 1.3],\n","       [6.4, 2.9, 4.3, 1.3],\n","       [5.6, 2.8, 4.9, 2. ],\n","       [5.9, 3. , 5.1, 1.8],\n","       [5.4, 3.4, 1.7, 0.2],\n","       [6.1, 2.8, 4. , 1.3],\n","       [4.9, 2.5, 4.5, 1.7],\n","       [5.8, 4. , 1.2, 0.2],\n","       [5.8, 2.6, 4. , 1.2],\n","       [7.1, 3. , 5.9, 2.1]])"]},"metadata":{},"execution_count":182}],"source":["X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y1BLQqb1TYiw","executionInfo":{"status":"ok","timestamp":1707898221191,"user_tz":-540,"elapsed":12,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"28b7d1c7-88f2-4dc0-f26e-293b87ca159d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.41176471, 0.40909091, 0.55357143, 0.5       ],\n","       [0.97058824, 0.45454545, 0.98214286, 0.83333333],\n","       [0.38235294, 0.45454545, 0.60714286, 0.58333333],\n","       [0.23529412, 0.68181818, 0.05357143, 0.04166667],\n","       [1.        , 0.36363636, 1.        , 0.79166667],\n","       [0.44117647, 0.31818182, 0.53571429, 0.375     ],\n","       [0.26470588, 0.63636364, 0.05357143, 0.04166667],\n","       [0.20588235, 0.68181818, 0.03571429, 0.08333333],\n","       [0.23529412, 0.81818182, 0.14285714, 0.125     ],\n","       [0.20588235, 0.        , 0.42857143, 0.375     ],\n","       [0.58823529, 0.31818182, 0.67857143, 0.70833333],\n","       [0.14705882, 0.63636364, 0.14285714, 0.04166667],\n","       [0.20588235, 0.45454545, 0.08928571, 0.04166667],\n","       [0.23529412, 0.59090909, 0.10714286, 0.16666667],\n","       [0.38235294, 0.31818182, 0.55357143, 0.5       ],\n","       [0.23529412, 0.63636364, 0.07142857, 0.04166667],\n","       [0.41176471, 0.45454545, 0.55357143, 0.45833333],\n","       [1.        , 0.81818182, 1.        , 0.875     ],\n","       [0.08823529, 0.54545455, 0.05357143, 0.04166667],\n","       [0.55882353, 0.40909091, 0.57142857, 0.5       ],\n","       [0.41176471, 0.22727273, 0.69642857, 0.79166667],\n","       [0.35294118, 1.        , 0.05357143, 0.04166667],\n","       [0.5       , 0.45454545, 0.66071429, 0.70833333],\n","       [0.44117647, 0.31818182, 0.71428571, 0.75      ],\n","       [0.5       , 0.09090909, 0.51785714, 0.375     ],\n","       [0.32352941, 0.45454545, 0.60714286, 0.58333333],\n","       [0.55882353, 0.63636364, 0.76785714, 0.91666667],\n","       [0.35294118, 0.13636364, 0.51785714, 0.5       ],\n","       [0.32352941, 0.86363636, 0.10714286, 0.125     ],\n","       [0.20588235, 0.13636364, 0.39285714, 0.375     ],\n","       [0.61764706, 0.31818182, 0.75      , 0.75      ],\n","       [0.20588235, 0.59090909, 0.05357143, 0.04166667],\n","       [0.20588235, 0.54545455, 0.01785714, 0.04166667],\n","       [0.35294118, 0.18181818, 0.48214286, 0.41666667],\n","       [0.70588235, 0.45454545, 0.69642857, 0.66666667],\n","       [0.17647059, 0.5       , 0.07142857, 0.04166667],\n","       [0.44117647, 0.36363636, 0.71428571, 0.95833333],\n","       [0.20588235, 0.63636364, 0.07142857, 0.04166667],\n","       [0.20588235, 0.68181818, 0.08928571, 0.20833333],\n","       [0.47058824, 0.54545455, 0.66071429, 0.70833333],\n","       [0.23529412, 0.22727273, 0.33928571, 0.41666667],\n","       [0.76470588, 0.54545455, 0.82142857, 0.91666667],\n","       [0.5       , 0.31818182, 0.71428571, 0.625     ],\n","       [0.52941176, 0.27272727, 0.80357143, 0.54166667],\n","       [1.        , 0.45454545, 0.89285714, 0.91666667],\n","       [0.35294118, 0.22727273, 0.51785714, 0.5       ],\n","       [0.02941176, 0.40909091, 0.05357143, 0.04166667],\n","       [0.        , 0.45454545, 0.        , 0.        ],\n","       [0.5       , 0.09090909, 0.69642857, 0.58333333],\n","       [0.85294118, 0.54545455, 0.875     , 0.70833333],\n","       [0.08823529, 0.5       , 0.07142857, 0.04166667],\n","       [0.23529412, 0.68181818, 0.05357143, 0.08333333],\n","       [0.02941176, 0.45454545, 0.03571429, 0.04166667],\n","       [0.58823529, 0.22727273, 0.67857143, 0.58333333],\n","       [0.58823529, 0.63636364, 0.80357143, 0.95833333],\n","       [0.08823529, 0.63636364, 0.05357143, 0.08333333],\n","       [0.73529412, 0.45454545, 0.78571429, 0.83333333],\n","       [0.58823529, 0.59090909, 0.875     , 1.        ],\n","       [0.11764706, 0.54545455, 0.03571429, 0.04166667],\n","       [0.52941176, 0.40909091, 0.64285714, 0.54166667],\n","       [0.64705882, 0.36363636, 0.625     , 0.58333333],\n","       [0.55882353, 0.36363636, 0.66071429, 0.70833333],\n","       [0.79411765, 0.54545455, 0.64285714, 0.54166667],\n","       [0.61764706, 0.54545455, 0.75      , 0.91666667],\n","       [0.23529412, 0.81818182, 0.08928571, 0.04166667],\n","       [0.76470588, 0.5       , 0.76785714, 0.83333333],\n","       [0.47058824, 0.45454545, 0.55357143, 0.58333333],\n","       [0.64705882, 0.45454545, 0.73214286, 0.79166667],\n","       [0.41176471, 0.27272727, 0.42857143, 0.375     ],\n","       [0.26470588, 0.31818182, 0.5       , 0.54166667],\n","       [0.52941176, 0.45454545, 0.625     , 0.54166667],\n","       [0.05882353, 0.13636364, 0.03571429, 0.08333333],\n","       [0.67647059, 0.40909091, 0.625     , 0.5       ],\n","       [0.35294118, 0.27272727, 0.58928571, 0.45833333],\n","       [0.29411765, 0.77272727, 0.07142857, 0.04166667],\n","       [0.38235294, 0.45454545, 0.53571429, 0.5       ],\n","       [0.88235294, 0.40909091, 0.92857143, 0.70833333],\n","       [0.70588235, 0.59090909, 0.82142857, 0.83333333],\n","       [0.23529412, 0.77272727, 0.07142857, 0.125     ],\n","       [0.17647059, 0.18181818, 0.39285714, 0.375     ],\n","       [0.70588235, 0.59090909, 0.82142857, 1.        ],\n","       [0.85294118, 0.45454545, 0.83928571, 0.625     ],\n","       [0.17647059, 0.72727273, 0.05357143, 0.        ],\n","       [0.70588235, 0.5       , 0.80357143, 0.95833333],\n","       [0.17647059, 0.45454545, 0.05357143, 0.04166667],\n","       [0.76470588, 0.5       , 0.67857143, 0.58333333],\n","       [0.91176471, 0.36363636, 0.89285714, 0.75      ],\n","       [0.58823529, 0.40909091, 0.80357143, 0.70833333],\n","       [0.41176471, 0.36363636, 0.53571429, 0.5       ],\n","       [0.64705882, 0.45454545, 0.78571429, 0.70833333],\n","       [0.58823529, 0.13636364, 0.58928571, 0.5       ],\n","       [0.61764706, 0.40909091, 0.57142857, 0.5       ],\n","       [0.38235294, 0.36363636, 0.67857143, 0.79166667],\n","       [0.47058824, 0.45454545, 0.71428571, 0.70833333],\n","       [0.32352941, 0.63636364, 0.10714286, 0.04166667],\n","       [0.52941176, 0.36363636, 0.51785714, 0.5       ],\n","       [0.17647059, 0.22727273, 0.60714286, 0.66666667],\n","       [0.44117647, 0.90909091, 0.01785714, 0.04166667],\n","       [0.44117647, 0.27272727, 0.51785714, 0.45833333],\n","       [0.82352941, 0.45454545, 0.85714286, 0.83333333]])"]},"metadata":{},"execution_count":183}],"source":["scaled_X_train"]},{"cell_type":"markdown","metadata":{"id":"Dd-XRubwTYix"},"source":["## Building the Network with Keras\n","\n","Let's build a simple neural network!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNZmodryTYix"},"outputs":[],"source":["from keras.models import Sequential #Sequential 모델은 신경망을 순차적으로 쌓는 데 사용됩니다.\n","#이는 입력층, 은닉층, 출력층 등을 순차적으로 쌓아 간단한 모델부터 복잡한 모델까지 만들 수 있도록 합니다.\n","\n","from keras.layers import Dense #Dense 층은 fully connected 층을 의미하며, 모든 입력 뉴런과 출력 뉴런이 연결된 층입니다.\n","#이 층은 신경망에서 가장 일반적으로 사용되는 층 중 하나이며, 입력과 출력 사이에 있는 모든 뉴런이 서로 연결되어 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjE5BP4WTYix"},"outputs":[],"source":["#다층 퍼셉트론(Multi-Layer Perceptron, MLP)을 구축하고 컴파일하는 과정\n","\n","model = Sequential()\n","# 각각 8개의 뉴런으로 이루어진 2개의 은닉층과 3개의 출력 뉴런으로 이루어진 출력층으로 구성\n","model.add(Dense(8, input_dim=4, activation='relu')) #첫 번째 은닉층을 추가합니다. 이 층은 8개의 뉴런을 가지며, 입력 차원은 4입니다.\n","#activation은 활성화 함수로 ReLU 함수를 사용합니다.\n","\n","model.add(Dense(8, input_dim=4, activation='relu')) #두 번째 은닉층을 추가합니다.\n","\n","model.add(Dense(3, activation='softmax')) #출력층을 추가합니다. 이 층은 3개의 뉴런을 가지며, 클래스 수에 해당하는 출력 차원을 가집니다.\n","#activation은 확률값을 출력하기 위해 softmax 함수를 사용\n","#일반적으로 분류 문제에서는 마지막 층에서 softmax 함수를 사용하여 모델이 각 클래스에 속할 확률을 예측할 수 있도록 합니다.\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#모델을 컴파일합니다. 이때 손실 함수로 categorical crossentropy를, 옵티마이저로는 Adam을 사용합니다. 성능 평가 지표로는 정확도(accuracy)를 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-60DIstCTYix","executionInfo":{"status":"ok","timestamp":1707898221644,"user_tz":-540,"elapsed":463,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"89cb904d-f0ab-4245-f408-a6f563c5576f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_15 (Dense)            (None, 8)                 40        \n","                                                                 \n"," dense_16 (Dense)            (None, 8)                 72        \n","                                                                 \n"," dense_17 (Dense)            (None, 3)                 27        \n","                                                                 \n","=================================================================\n","Total params: 139 (556.00 Byte)\n","Trainable params: 139 (556.00 Byte)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"8TU74xGcTYix"},"source":["## Fit (Train) the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eiRK_1yTYix","executionInfo":{"status":"ok","timestamp":1707898225155,"user_tz":-540,"elapsed":3515,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"01d42f34-8846-4d2c-f527-14702d302ade"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","4/4 - 1s - loss: 1.1630 - accuracy: 0.3100 - 718ms/epoch - 180ms/step\n","Epoch 2/150\n","4/4 - 0s - loss: 1.1540 - accuracy: 0.3100 - 11ms/epoch - 3ms/step\n","Epoch 3/150\n","4/4 - 0s - loss: 1.1455 - accuracy: 0.3000 - 12ms/epoch - 3ms/step\n","Epoch 4/150\n","4/4 - 0s - loss: 1.1380 - accuracy: 0.3000 - 11ms/epoch - 3ms/step\n","Epoch 5/150\n","4/4 - 0s - loss: 1.1315 - accuracy: 0.3000 - 13ms/epoch - 3ms/step\n","Epoch 6/150\n","4/4 - 0s - loss: 1.1252 - accuracy: 0.3000 - 11ms/epoch - 3ms/step\n","Epoch 7/150\n","4/4 - 0s - loss: 1.1193 - accuracy: 0.3100 - 11ms/epoch - 3ms/step\n","Epoch 8/150\n","4/4 - 0s - loss: 1.1140 - accuracy: 0.3100 - 12ms/epoch - 3ms/step\n","Epoch 9/150\n","4/4 - 0s - loss: 1.1090 - accuracy: 0.3100 - 11ms/epoch - 3ms/step\n","Epoch 10/150\n","4/4 - 0s - loss: 1.1040 - accuracy: 0.3100 - 12ms/epoch - 3ms/step\n","Epoch 11/150\n","4/4 - 0s - loss: 1.0993 - accuracy: 0.3100 - 12ms/epoch - 3ms/step\n","Epoch 12/150\n","4/4 - 0s - loss: 1.0945 - accuracy: 0.3100 - 11ms/epoch - 3ms/step\n","Epoch 13/150\n","4/4 - 0s - loss: 1.0897 - accuracy: 0.3300 - 13ms/epoch - 3ms/step\n","Epoch 14/150\n","4/4 - 0s - loss: 1.0848 - accuracy: 0.3500 - 13ms/epoch - 3ms/step\n","Epoch 15/150\n","4/4 - 0s - loss: 1.0798 - accuracy: 0.3900 - 12ms/epoch - 3ms/step\n","Epoch 16/150\n","4/4 - 0s - loss: 1.0745 - accuracy: 0.4200 - 13ms/epoch - 3ms/step\n","Epoch 17/150\n","4/4 - 0s - loss: 1.0695 - accuracy: 0.4800 - 12ms/epoch - 3ms/step\n","Epoch 18/150\n","4/4 - 0s - loss: 1.0643 - accuracy: 0.5800 - 16ms/epoch - 4ms/step\n","Epoch 19/150\n","4/4 - 0s - loss: 1.0590 - accuracy: 0.6600 - 11ms/epoch - 3ms/step\n","Epoch 20/150\n","4/4 - 0s - loss: 1.0540 - accuracy: 0.6700 - 11ms/epoch - 3ms/step\n","Epoch 21/150\n","4/4 - 0s - loss: 1.0495 - accuracy: 0.6200 - 12ms/epoch - 3ms/step\n","Epoch 22/150\n","4/4 - 0s - loss: 1.0448 - accuracy: 0.6100 - 11ms/epoch - 3ms/step\n","Epoch 23/150\n","4/4 - 0s - loss: 1.0405 - accuracy: 0.5800 - 11ms/epoch - 3ms/step\n","Epoch 24/150\n","4/4 - 0s - loss: 1.0355 - accuracy: 0.5900 - 12ms/epoch - 3ms/step\n","Epoch 25/150\n","4/4 - 0s - loss: 1.0308 - accuracy: 0.6000 - 12ms/epoch - 3ms/step\n","Epoch 26/150\n","4/4 - 0s - loss: 1.0261 - accuracy: 0.6000 - 15ms/epoch - 4ms/step\n","Epoch 27/150\n","4/4 - 0s - loss: 1.0216 - accuracy: 0.6100 - 22ms/epoch - 6ms/step\n","Epoch 28/150\n","4/4 - 0s - loss: 1.0167 - accuracy: 0.6200 - 12ms/epoch - 3ms/step\n","Epoch 29/150\n","4/4 - 0s - loss: 1.0119 - accuracy: 0.6200 - 12ms/epoch - 3ms/step\n","Epoch 30/150\n","4/4 - 0s - loss: 1.0070 - accuracy: 0.6200 - 12ms/epoch - 3ms/step\n","Epoch 31/150\n","4/4 - 0s - loss: 1.0016 - accuracy: 0.6200 - 11ms/epoch - 3ms/step\n","Epoch 32/150\n","4/4 - 0s - loss: 0.9963 - accuracy: 0.6100 - 11ms/epoch - 3ms/step\n","Epoch 33/150\n","4/4 - 0s - loss: 0.9907 - accuracy: 0.6100 - 11ms/epoch - 3ms/step\n","Epoch 34/150\n","4/4 - 0s - loss: 0.9853 - accuracy: 0.6100 - 14ms/epoch - 3ms/step\n","Epoch 35/150\n","4/4 - 0s - loss: 0.9796 - accuracy: 0.6100 - 12ms/epoch - 3ms/step\n","Epoch 36/150\n","4/4 - 0s - loss: 0.9741 - accuracy: 0.6200 - 12ms/epoch - 3ms/step\n","Epoch 37/150\n","4/4 - 0s - loss: 0.9687 - accuracy: 0.6200 - 18ms/epoch - 4ms/step\n","Epoch 38/150\n","4/4 - 0s - loss: 0.9629 - accuracy: 0.6300 - 14ms/epoch - 3ms/step\n","Epoch 39/150\n","4/4 - 0s - loss: 0.9573 - accuracy: 0.6300 - 14ms/epoch - 4ms/step\n","Epoch 40/150\n","4/4 - 0s - loss: 0.9518 - accuracy: 0.6300 - 11ms/epoch - 3ms/step\n","Epoch 41/150\n","4/4 - 0s - loss: 0.9459 - accuracy: 0.6400 - 11ms/epoch - 3ms/step\n","Epoch 42/150\n","4/4 - 0s - loss: 0.9399 - accuracy: 0.6400 - 12ms/epoch - 3ms/step\n","Epoch 43/150\n","4/4 - 0s - loss: 0.9339 - accuracy: 0.6400 - 13ms/epoch - 3ms/step\n","Epoch 44/150\n","4/4 - 0s - loss: 0.9281 - accuracy: 0.6300 - 12ms/epoch - 3ms/step\n","Epoch 45/150\n","4/4 - 0s - loss: 0.9214 - accuracy: 0.6200 - 12ms/epoch - 3ms/step\n","Epoch 46/150\n","4/4 - 0s - loss: 0.9157 - accuracy: 0.6200 - 17ms/epoch - 4ms/step\n","Epoch 47/150\n","4/4 - 0s - loss: 0.9097 - accuracy: 0.6300 - 13ms/epoch - 3ms/step\n","Epoch 48/150\n","4/4 - 0s - loss: 0.9035 - accuracy: 0.6300 - 11ms/epoch - 3ms/step\n","Epoch 49/150\n","4/4 - 0s - loss: 0.8970 - accuracy: 0.6300 - 11ms/epoch - 3ms/step\n","Epoch 50/150\n","4/4 - 0s - loss: 0.8907 - accuracy: 0.6500 - 12ms/epoch - 3ms/step\n","Epoch 51/150\n","4/4 - 0s - loss: 0.8841 - accuracy: 0.6700 - 12ms/epoch - 3ms/step\n","Epoch 52/150\n","4/4 - 0s - loss: 0.8780 - accuracy: 0.6800 - 12ms/epoch - 3ms/step\n","Epoch 53/150\n","4/4 - 0s - loss: 0.8716 - accuracy: 0.6800 - 12ms/epoch - 3ms/step\n","Epoch 54/150\n","4/4 - 0s - loss: 0.8655 - accuracy: 0.7000 - 13ms/epoch - 3ms/step\n","Epoch 55/150\n","4/4 - 0s - loss: 0.8590 - accuracy: 0.7100 - 12ms/epoch - 3ms/step\n","Epoch 56/150\n","4/4 - 0s - loss: 0.8529 - accuracy: 0.7100 - 12ms/epoch - 3ms/step\n","Epoch 57/150\n","4/4 - 0s - loss: 0.8469 - accuracy: 0.7100 - 16ms/epoch - 4ms/step\n","Epoch 58/150\n","4/4 - 0s - loss: 0.8408 - accuracy: 0.7200 - 12ms/epoch - 3ms/step\n","Epoch 59/150\n","4/4 - 0s - loss: 0.8350 - accuracy: 0.7200 - 12ms/epoch - 3ms/step\n","Epoch 60/150\n","4/4 - 0s - loss: 0.8295 - accuracy: 0.7100 - 14ms/epoch - 3ms/step\n","Epoch 61/150\n","4/4 - 0s - loss: 0.8239 - accuracy: 0.7000 - 14ms/epoch - 4ms/step\n","Epoch 62/150\n","4/4 - 0s - loss: 0.8186 - accuracy: 0.7000 - 12ms/epoch - 3ms/step\n","Epoch 63/150\n","4/4 - 0s - loss: 0.8137 - accuracy: 0.7000 - 13ms/epoch - 3ms/step\n","Epoch 64/150\n","4/4 - 0s - loss: 0.8085 - accuracy: 0.7000 - 12ms/epoch - 3ms/step\n","Epoch 65/150\n","4/4 - 0s - loss: 0.8036 - accuracy: 0.7000 - 11ms/epoch - 3ms/step\n","Epoch 66/150\n","4/4 - 0s - loss: 0.7989 - accuracy: 0.7300 - 12ms/epoch - 3ms/step\n","Epoch 67/150\n","4/4 - 0s - loss: 0.7945 - accuracy: 0.7100 - 14ms/epoch - 3ms/step\n","Epoch 68/150\n","4/4 - 0s - loss: 0.7901 - accuracy: 0.7100 - 12ms/epoch - 3ms/step\n","Epoch 69/150\n","4/4 - 0s - loss: 0.7859 - accuracy: 0.7200 - 12ms/epoch - 3ms/step\n","Epoch 70/150\n","4/4 - 0s - loss: 0.7819 - accuracy: 0.7200 - 13ms/epoch - 3ms/step\n","Epoch 71/150\n","4/4 - 0s - loss: 0.7777 - accuracy: 0.7300 - 14ms/epoch - 3ms/step\n","Epoch 72/150\n","4/4 - 0s - loss: 0.7738 - accuracy: 0.7400 - 12ms/epoch - 3ms/step\n","Epoch 73/150\n","4/4 - 0s - loss: 0.7699 - accuracy: 0.7300 - 12ms/epoch - 3ms/step\n","Epoch 74/150\n","4/4 - 0s - loss: 0.7661 - accuracy: 0.7300 - 13ms/epoch - 3ms/step\n","Epoch 75/150\n","4/4 - 0s - loss: 0.7625 - accuracy: 0.7400 - 14ms/epoch - 3ms/step\n","Epoch 76/150\n","4/4 - 0s - loss: 0.7590 - accuracy: 0.7400 - 17ms/epoch - 4ms/step\n","Epoch 77/150\n","4/4 - 0s - loss: 0.7556 - accuracy: 0.7400 - 12ms/epoch - 3ms/step\n","Epoch 78/150\n","4/4 - 0s - loss: 0.7523 - accuracy: 0.7500 - 13ms/epoch - 3ms/step\n","Epoch 79/150\n","4/4 - 0s - loss: 0.7492 - accuracy: 0.7800 - 12ms/epoch - 3ms/step\n","Epoch 80/150\n","4/4 - 0s - loss: 0.7461 - accuracy: 0.8100 - 12ms/epoch - 3ms/step\n","Epoch 81/150\n","4/4 - 0s - loss: 0.7431 - accuracy: 0.8200 - 12ms/epoch - 3ms/step\n","Epoch 82/150\n","4/4 - 0s - loss: 0.7401 - accuracy: 0.8100 - 12ms/epoch - 3ms/step\n","Epoch 83/150\n","4/4 - 0s - loss: 0.7373 - accuracy: 0.8100 - 12ms/epoch - 3ms/step\n","Epoch 84/150\n","4/4 - 0s - loss: 0.7345 - accuracy: 0.8100 - 12ms/epoch - 3ms/step\n","Epoch 85/150\n","4/4 - 0s - loss: 0.7317 - accuracy: 0.8100 - 12ms/epoch - 3ms/step\n","Epoch 86/150\n","4/4 - 0s - loss: 0.7290 - accuracy: 0.8100 - 11ms/epoch - 3ms/step\n","Epoch 87/150\n","4/4 - 0s - loss: 0.7265 - accuracy: 0.9200 - 11ms/epoch - 3ms/step\n","Epoch 88/150\n","4/4 - 0s - loss: 0.7239 - accuracy: 0.9200 - 12ms/epoch - 3ms/step\n","Epoch 89/150\n","4/4 - 0s - loss: 0.7215 - accuracy: 0.9200 - 16ms/epoch - 4ms/step\n","Epoch 90/150\n","4/4 - 0s - loss: 0.7190 - accuracy: 0.9200 - 18ms/epoch - 4ms/step\n","Epoch 91/150\n","4/4 - 0s - loss: 0.7167 - accuracy: 0.9200 - 12ms/epoch - 3ms/step\n","Epoch 92/150\n","4/4 - 0s - loss: 0.7144 - accuracy: 0.9200 - 11ms/epoch - 3ms/step\n","Epoch 93/150\n","4/4 - 0s - loss: 0.7121 - accuracy: 0.9100 - 11ms/epoch - 3ms/step\n","Epoch 94/150\n","4/4 - 0s - loss: 0.7099 - accuracy: 0.9100 - 11ms/epoch - 3ms/step\n","Epoch 95/150\n","4/4 - 0s - loss: 0.7078 - accuracy: 0.9100 - 14ms/epoch - 3ms/step\n","Epoch 96/150\n","4/4 - 0s - loss: 0.7055 - accuracy: 0.9100 - 12ms/epoch - 3ms/step\n","Epoch 97/150\n","4/4 - 0s - loss: 0.7034 - accuracy: 0.9200 - 12ms/epoch - 3ms/step\n","Epoch 98/150\n","4/4 - 0s - loss: 0.7012 - accuracy: 0.9200 - 19ms/epoch - 5ms/step\n","Epoch 99/150\n","4/4 - 0s - loss: 0.6990 - accuracy: 0.9200 - 15ms/epoch - 4ms/step\n","Epoch 100/150\n","4/4 - 0s - loss: 0.6969 - accuracy: 0.9300 - 19ms/epoch - 5ms/step\n","Epoch 101/150\n","4/4 - 0s - loss: 0.6948 - accuracy: 0.9300 - 18ms/epoch - 5ms/step\n","Epoch 102/150\n","4/4 - 0s - loss: 0.6926 - accuracy: 0.9400 - 17ms/epoch - 4ms/step\n","Epoch 103/150\n","4/4 - 0s - loss: 0.6907 - accuracy: 0.9300 - 14ms/epoch - 3ms/step\n","Epoch 104/150\n","4/4 - 0s - loss: 0.6887 - accuracy: 0.9200 - 14ms/epoch - 4ms/step\n","Epoch 105/150\n","4/4 - 0s - loss: 0.6868 - accuracy: 0.9200 - 16ms/epoch - 4ms/step\n","Epoch 106/150\n","4/4 - 0s - loss: 0.6848 - accuracy: 0.9200 - 18ms/epoch - 4ms/step\n","Epoch 107/150\n","4/4 - 0s - loss: 0.6828 - accuracy: 0.9200 - 16ms/epoch - 4ms/step\n","Epoch 108/150\n","4/4 - 0s - loss: 0.6807 - accuracy: 0.9200 - 15ms/epoch - 4ms/step\n","Epoch 109/150\n","4/4 - 0s - loss: 0.6787 - accuracy: 0.9300 - 14ms/epoch - 4ms/step\n","Epoch 110/150\n","4/4 - 0s - loss: 0.6767 - accuracy: 0.9300 - 16ms/epoch - 4ms/step\n","Epoch 111/150\n","4/4 - 0s - loss: 0.6747 - accuracy: 0.9300 - 13ms/epoch - 3ms/step\n","Epoch 112/150\n","4/4 - 0s - loss: 0.6728 - accuracy: 0.9400 - 14ms/epoch - 3ms/step\n","Epoch 113/150\n","4/4 - 0s - loss: 0.6709 - accuracy: 0.9400 - 17ms/epoch - 4ms/step\n","Epoch 114/150\n","4/4 - 0s - loss: 0.6690 - accuracy: 0.9300 - 15ms/epoch - 4ms/step\n","Epoch 115/150\n","4/4 - 0s - loss: 0.6670 - accuracy: 0.9200 - 14ms/epoch - 3ms/step\n","Epoch 116/150\n","4/4 - 0s - loss: 0.6651 - accuracy: 0.9200 - 15ms/epoch - 4ms/step\n","Epoch 117/150\n","4/4 - 0s - loss: 0.6632 - accuracy: 0.9200 - 15ms/epoch - 4ms/step\n","Epoch 118/150\n","4/4 - 0s - loss: 0.6613 - accuracy: 0.9200 - 15ms/epoch - 4ms/step\n","Epoch 119/150\n","4/4 - 0s - loss: 0.6595 - accuracy: 0.9300 - 20ms/epoch - 5ms/step\n","Epoch 120/150\n","4/4 - 0s - loss: 0.6575 - accuracy: 0.9300 - 18ms/epoch - 4ms/step\n","Epoch 121/150\n","4/4 - 0s - loss: 0.6557 - accuracy: 0.9400 - 19ms/epoch - 5ms/step\n","Epoch 122/150\n","4/4 - 0s - loss: 0.6537 - accuracy: 0.9500 - 21ms/epoch - 5ms/step\n","Epoch 123/150\n","4/4 - 0s - loss: 0.6516 - accuracy: 0.9500 - 18ms/epoch - 5ms/step\n","Epoch 124/150\n","4/4 - 0s - loss: 0.6496 - accuracy: 0.9500 - 19ms/epoch - 5ms/step\n","Epoch 125/150\n","4/4 - 0s - loss: 0.6476 - accuracy: 0.9500 - 17ms/epoch - 4ms/step\n","Epoch 126/150\n","4/4 - 0s - loss: 0.6457 - accuracy: 0.9500 - 16ms/epoch - 4ms/step\n","Epoch 127/150\n","4/4 - 0s - loss: 0.6436 - accuracy: 0.9600 - 16ms/epoch - 4ms/step\n","Epoch 128/150\n","4/4 - 0s - loss: 0.6416 - accuracy: 0.9600 - 14ms/epoch - 4ms/step\n","Epoch 129/150\n","4/4 - 0s - loss: 0.6398 - accuracy: 0.9600 - 14ms/epoch - 3ms/step\n","Epoch 130/150\n","4/4 - 0s - loss: 0.6377 - accuracy: 0.9500 - 14ms/epoch - 4ms/step\n","Epoch 131/150\n","4/4 - 0s - loss: 0.6355 - accuracy: 0.9500 - 15ms/epoch - 4ms/step\n","Epoch 132/150\n","4/4 - 0s - loss: 0.6334 - accuracy: 0.9600 - 14ms/epoch - 4ms/step\n","Epoch 133/150\n","4/4 - 0s - loss: 0.6314 - accuracy: 0.9600 - 15ms/epoch - 4ms/step\n","Epoch 134/150\n","4/4 - 0s - loss: 0.6294 - accuracy: 0.9600 - 14ms/epoch - 4ms/step\n","Epoch 135/150\n","4/4 - 0s - loss: 0.6272 - accuracy: 0.9600 - 14ms/epoch - 4ms/step\n","Epoch 136/150\n","4/4 - 0s - loss: 0.6251 - accuracy: 0.9600 - 14ms/epoch - 3ms/step\n","Epoch 137/150\n","4/4 - 0s - loss: 0.6229 - accuracy: 0.9600 - 14ms/epoch - 4ms/step\n","Epoch 138/150\n","4/4 - 0s - loss: 0.6208 - accuracy: 0.9600 - 14ms/epoch - 4ms/step\n","Epoch 139/150\n","4/4 - 0s - loss: 0.6186 - accuracy: 0.9600 - 14ms/epoch - 3ms/step\n","Epoch 140/150\n","4/4 - 0s - loss: 0.6164 - accuracy: 0.9600 - 14ms/epoch - 4ms/step\n","Epoch 141/150\n","4/4 - 0s - loss: 0.6145 - accuracy: 0.9700 - 14ms/epoch - 3ms/step\n","Epoch 142/150\n","4/4 - 0s - loss: 0.6130 - accuracy: 0.9700 - 28ms/epoch - 7ms/step\n","Epoch 143/150\n","4/4 - 0s - loss: 0.6111 - accuracy: 0.9700 - 20ms/epoch - 5ms/step\n","Epoch 144/150\n","4/4 - 0s - loss: 0.6088 - accuracy: 0.9700 - 14ms/epoch - 3ms/step\n","Epoch 145/150\n","4/4 - 0s - loss: 0.6060 - accuracy: 0.9700 - 15ms/epoch - 4ms/step\n","Epoch 146/150\n","4/4 - 0s - loss: 0.6041 - accuracy: 0.9700 - 14ms/epoch - 4ms/step\n","Epoch 147/150\n","4/4 - 0s - loss: 0.6025 - accuracy: 0.9600 - 16ms/epoch - 4ms/step\n","Epoch 148/150\n","4/4 - 0s - loss: 0.5999 - accuracy: 0.9600 - 17ms/epoch - 4ms/step\n","Epoch 149/150\n","4/4 - 0s - loss: 0.5969 - accuracy: 0.9700 - 15ms/epoch - 4ms/step\n","Epoch 150/150\n","4/4 - 0s - loss: 0.5943 - accuracy: 0.9700 - 15ms/epoch - 4ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b4f820c8820>"]},"metadata":{},"execution_count":187}],"source":["# Play around with number of epochs as well!\n","model.fit(scaled_X_train,y_train,epochs=150, verbose=2)\n","#fit() 메서드는 학습 데이터와 레이블 데이터를 받아서 모델을 학습시킵니다.\n","#여기서 scaled_X_train은 스케일링된 특징 데이터이고, y_train은 원-핫 인코딩된 레이블 데이터입니다.\n","#erbose=2는 학습 진행 상황을 얼마나 자세하게 출력할 것인지를 지정하는 매개변수입니다.\n","#verbose가 2로 설정되면 에포크 당 한 줄의 출력이 나타납니다."]},{"cell_type":"markdown","metadata":{"id":"G6MXJSOhTYiy"},"source":["## Predicting New Unseen Data\n","\n","Let's see how we did by predicting on **new data**. Remember, our model has **never** seen the test data that we scaled previously! This process is the exact same process you would use on totally brand new data. For example , a brand new bank note that you just analyzed ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58aH7Z7nTYiy","executionInfo":{"status":"ok","timestamp":1707898225155,"user_tz":-540,"elapsed":16,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"cf88dda9-0784-4bd7-f0c8-d94af1e75a9e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.52941176,  0.36363636,  0.64285714,  0.45833333],\n","       [ 0.41176471,  0.81818182,  0.10714286,  0.08333333],\n","       [ 1.        ,  0.27272727,  1.03571429,  0.91666667],\n","       [ 0.5       ,  0.40909091,  0.60714286,  0.58333333],\n","       [ 0.73529412,  0.36363636,  0.66071429,  0.54166667],\n","       [ 0.32352941,  0.63636364,  0.07142857,  0.125     ],\n","       [ 0.38235294,  0.40909091,  0.44642857,  0.5       ],\n","       [ 0.76470588,  0.5       ,  0.71428571,  0.91666667],\n","       [ 0.55882353,  0.09090909,  0.60714286,  0.58333333],\n","       [ 0.44117647,  0.31818182,  0.5       ,  0.45833333],\n","       [ 0.64705882,  0.54545455,  0.71428571,  0.79166667],\n","       [ 0.14705882,  0.45454545,  0.05357143,  0.        ],\n","       [ 0.35294118,  0.68181818,  0.03571429,  0.04166667],\n","       [ 0.17647059,  0.5       ,  0.07142857,  0.        ],\n","       [ 0.23529412,  0.81818182,  0.07142857,  0.08333333],\n","       [ 0.58823529,  0.59090909,  0.64285714,  0.625     ],\n","       [ 0.64705882,  0.45454545,  0.83928571,  0.875     ],\n","       [ 0.38235294,  0.22727273,  0.5       ,  0.41666667],\n","       [ 0.41176471,  0.36363636,  0.60714286,  0.5       ],\n","       [ 0.61764706,  0.36363636,  0.80357143,  0.875     ],\n","       [ 0.11764706,  0.54545455,  0.08928571,  0.04166667],\n","       [ 0.52941176,  0.45454545,  0.67857143,  0.70833333],\n","       [ 0.20588235,  0.63636364,  0.08928571,  0.125     ],\n","       [ 0.61764706,  0.36363636,  0.80357143,  0.83333333],\n","       [ 1.05882353,  0.81818182,  0.94642857,  0.79166667],\n","       [ 0.70588235,  0.45454545,  0.73214286,  0.91666667],\n","       [ 0.70588235,  0.22727273,  0.83928571,  0.70833333],\n","       [ 0.73529412,  0.54545455,  0.85714286,  0.91666667],\n","       [ 0.14705882,  0.45454545,  0.05357143,  0.08333333],\n","       [ 0.14705882,  0.5       ,  0.08928571,  0.04166667],\n","       [ 0.08823529,  0.72727273, -0.01785714,  0.04166667],\n","       [ 0.41176471,  1.09090909,  0.07142857,  0.125     ],\n","       [ 0.70588235,  0.5       ,  0.58928571,  0.54166667],\n","       [ 0.14705882,  0.63636364,  0.08928571,  0.04166667],\n","       [ 0.02941176,  0.54545455,  0.03571429,  0.04166667],\n","       [ 0.58823529,  0.22727273,  0.69642857,  0.75      ],\n","       [ 0.61764706,  0.54545455,  0.60714286,  0.58333333],\n","       [ 0.26470588,  0.68181818,  0.07142857,  0.04166667],\n","       [ 0.20588235,  0.72727273,  0.05357143,  0.04166667],\n","       [ 0.26470588,  0.95454545,  0.07142857,  0.        ],\n","       [ 0.44117647,  0.31818182,  0.71428571,  0.75      ],\n","       [ 0.5       ,  0.63636364,  0.60714286,  0.625     ],\n","       [ 0.70588235,  0.5       ,  0.64285714,  0.58333333],\n","       [ 0.32352941,  0.86363636,  0.03571429,  0.125     ],\n","       [ 0.32352941,  0.77272727,  0.07142857,  0.04166667],\n","       [ 0.35294118,  0.18181818,  0.46428571,  0.375     ],\n","       [ 0.58823529,  0.36363636,  0.71428571,  0.58333333],\n","       [ 0.61764706,  0.5       ,  0.78571429,  0.70833333],\n","       [ 0.67647059,  0.45454545,  0.58928571,  0.54166667],\n","       [ 0.85294118,  0.72727273,  0.89285714,  1.        ]])"]},"metadata":{},"execution_count":188}],"source":["scaled_X_test #스케일링된 데이터"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"iOU7ed2mTYiy","executionInfo":{"status":"ok","timestamp":1707898225155,"user_tz":-540,"elapsed":11,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"fccd366a-33e0-4d89-b195-16439a58f0d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 5ms/step\n"]}],"source":["# Spits out probabilities by default.\n","predictions_x = model.predict(scaled_X_test)\n","#model.predict() 함수를 사용하여 스케일링된 테스트 데이터에 대한 예측 확률을 얻습니다.\n","#이 예측 확률은 각 샘플이 각 클래스에 속할 확률을 나타냅니다.\n","#예를 들어, 세 개의 클래스가 있다면 각 샘플에 대해 세 개의 확률이 반환됩니다."]},{"cell_type":"code","source":["predictions_x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjP7cvBAgO6v","executionInfo":{"status":"ok","timestamp":1707898225155,"user_tz":-540,"elapsed":8,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"d50a4afe-b96c-4bc0-8a67-9bf272ea888e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.23309591, 0.42141813, 0.3454859 ],\n","       [0.9847273 , 0.01209715, 0.00317552],\n","       [0.20430565, 0.32450768, 0.47118664],\n","       [0.22284108, 0.41815338, 0.35900566],\n","       [0.24632314, 0.42265788, 0.3310189 ],\n","       [0.97350305, 0.02048711, 0.00600977],\n","       [0.2664781 , 0.43456492, 0.29895708],\n","       [0.20346381, 0.37879506, 0.41774103],\n","       [0.21413955, 0.39017752, 0.39568287],\n","       [0.24336582, 0.44347152, 0.3131625 ],\n","       [0.2061033 , 0.38927835, 0.40461838],\n","       [0.9592898 , 0.03029318, 0.01041711],\n","       [0.9832078 , 0.01323067, 0.00356149],\n","       [0.9625701 , 0.02801795, 0.00941193],\n","       [0.9828483 , 0.0134973 , 0.00365452],\n","       [0.23194002, 0.42914104, 0.33891892],\n","       [0.19847974, 0.354228  , 0.44729233],\n","       [0.23566195, 0.43836966, 0.32596835],\n","       [0.21948022, 0.4163854 , 0.36413428],\n","       [0.19858031, 0.35373136, 0.4476884 ],\n","       [0.95969546, 0.03001266, 0.01029187],\n","       [0.20276402, 0.38974503, 0.40749094],\n","       [0.96833163, 0.02388553, 0.00778279],\n","       [0.19826727, 0.35527578, 0.44645706],\n","       [0.23298356, 0.38998607, 0.3770304 ],\n","       [0.1958708 , 0.3669401 , 0.43718913],\n","       [0.19941425, 0.34959224, 0.4509935 ],\n","       [0.19819838, 0.35561487, 0.44618678],\n","       [0.9521033 , 0.03552046, 0.01237609],\n","       [0.95724255, 0.0317047 , 0.01105275],\n","       [0.98131746, 0.01462767, 0.00405489],\n","       [0.9925644 , 0.00611722, 0.0013185 ],\n","       [0.2602025 , 0.4505481 , 0.28924936],\n","       [0.9687413 , 0.0236891 , 0.00756953],\n","       [0.96184576, 0.02845071, 0.00970341],\n","       [0.19632666, 0.364742  , 0.43893132],\n","       [0.24376668, 0.44056857, 0.31566492],\n","       [0.9780294 , 0.01703316, 0.00493742],\n","       [0.97972345, 0.01579743, 0.00447905],\n","       [0.9885983 , 0.00918018, 0.00222152],\n","       [0.19578391, 0.36735797, 0.43685818],\n","       [0.22913608, 0.43519974, 0.3356641 ],\n","       [0.24709605, 0.43350655, 0.31939748],\n","       [0.987933  , 0.00968613, 0.0023808 ],\n","       [0.9837558 , 0.01282361, 0.00342054],\n","       [0.24121366, 0.44229206, 0.3164943 ],\n","       [0.21402447, 0.39179954, 0.39417598],\n","       [0.19809796, 0.37240708, 0.42949498],\n","       [0.25446203, 0.4446231 , 0.3009149 ],\n","       [0.19764973, 0.35830784, 0.4440424 ]], dtype=float32)"]},"metadata":{},"execution_count":190}]},{"cell_type":"code","source":["predicted_classes_x = np.argmax(predictions_x, axis=1)\n","#예측 확률이 담긴 배열인 predictions_x에서 각 행에서 최댓값의 인덱스를 찾아 예측된 클래스로 변환하는 것입니다.\n","#axis=1은 각 행에서 최댓값의 인덱스를 찾겠다는 것을 의미합니다."],"metadata":{"id":"NRYrQmU8egjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_classes_x #원핫인코딩 값이 아닌 위치값으로 출력됐음. 그래서 y_test도 이렇게 변환해야 함."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45FdRKzTehlW","executionInfo":{"status":"ok","timestamp":1707898225156,"user_tz":-540,"elapsed":7,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"2f9ec957-4ee1-499e-f5b6-1e65c146bf8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n","       0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n","       0, 1, 2, 2, 1, 2])"]},"metadata":{},"execution_count":192}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBjIUp02TYiy"},"outputs":[],"source":["# model.predict_classes(scaled_X_test)"]},{"cell_type":"code","source":["# y_test도 위에처럼 바꾸기"],"metadata":{"id":"_8pnLkFmgqbL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test.argmax(axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qhX4xQTBgqpg","executionInfo":{"status":"ok","timestamp":1707898225156,"user_tz":-540,"elapsed":6,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"1831da6c-c81b-4372-d221-754230706437"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n","       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n","       0, 1, 2, 2, 1, 2])"]},"metadata":{},"execution_count":195}]},{"cell_type":"markdown","metadata":{"id":"wJWjPns-TYiy"},"source":["# Evaluating Model Performance\n","\n","So how well did we do? How do we actually measure \"well\". Is 95% accuracy good enough? It all depends on the situation. Also we need to take into account things like recall and precision. Make sure to watch the video discussion on classification evaluation before running this code!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H0kkDbUHTYiy"},"outputs":[],"source":["# model.metrics_names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U3p7YCf2TYiz","executionInfo":{"status":"ok","timestamp":1707898225466,"user_tz":-540,"elapsed":314,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"81b5cabd-4ac9-4251-cab8-4c7668d79ba4"},"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 8ms/step - loss: 0.5327 - accuracy: 0.9600\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.5326591730117798, 0.9599999785423279]"]},"metadata":{},"execution_count":197}],"source":["model.evaluate(x=scaled_X_test,y=y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"qeMl0L2OTYiz"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n","#confusion_matrix: 혼동 행렬(Confusion Matrix)을 계산하는 함수로, 예측된 클래스와 실제 클래스 간의 오차를 행렬로 표현합니다.\n","#이를 통해 모델의 성능을 평가할 때 사용됩니다.\n","\n","#classification_report: 분류 보고서(Classification Report)를 생성하는 함수로,\n","#정밀도(precision), 재현율(recall), F1-점수(F1-score) 등을 포함한 다양한 분류 지표를 계산하여 제공합니다.\n","\n","#accuracy_score: 정확도(Accuracy)를 계산하는 함수로, 모델의 전체적인 분류 정확도를 나타냅니다."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"bg0LGwoITYiz","executionInfo":{"status":"ok","timestamp":1707898225466,"user_tz":-540,"elapsed":11,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"145d972d-b85f-42d9-ca3a-704a6bd20e7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 5ms/step\n"]}],"source":["predictions_x=model.predict(scaled_X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JX241iZ-TYiz","executionInfo":{"status":"ok","timestamp":1707898225466,"user_tz":-540,"elapsed":9,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"261b9df9-47a8-43da-ccd3-873fbe518e0b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n","       0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n","       0, 1, 2, 2, 1, 2])"]},"metadata":{},"execution_count":200}],"source":["predicted_classes_x = np.argmax(predictions_x, axis=1)\n","predicted_classes_x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWU_R-b6TYiz","executionInfo":{"status":"ok","timestamp":1707898225466,"user_tz":-540,"elapsed":7,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"cbacc7a0-8fda-4d28-d9a8-ed8c022e2937"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n","       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n","       0, 1, 2, 2, 1, 2])"]},"metadata":{},"execution_count":201}],"source":["y_test.argmax(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1HIBJoRITYiz","executionInfo":{"status":"ok","timestamp":1707898225466,"user_tz":-540,"elapsed":6,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"22484a7c-b075-4fe0-e71c-7c2f67bcd364"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[19,  0,  0],\n","       [ 0, 14,  1],\n","       [ 0,  1, 15]])"]},"metadata":{},"execution_count":202}],"source":["confusion_matrix(y_test.argmax(axis=1),predicted_classes_x)\n","#이 행렬은 각 행은 실제 클래스를, 각 열은 예측된 클래스를 나타내며,\n","#행렬의 값은 해당 클래스가 얼마나 맞게 예측되었는지를 나타냅니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zS4Fl1PXTYiz","executionInfo":{"status":"ok","timestamp":1707898225466,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"bc55a450-f1f2-4366-fd51-a65b4668e566"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       0.93      0.93      0.93        15\n","           2       0.94      0.94      0.94        16\n","\n","    accuracy                           0.96        50\n","   macro avg       0.96      0.96      0.96        50\n","weighted avg       0.96      0.96      0.96        50\n","\n"]}],"source":["print(classification_report(y_test.argmax(axis=1),predicted_classes_x))\n","#정밀도(precision), 재현율(recall), F1-점수(F1-score) 등의 다양한 분류 지표가 포함"]},{"cell_type":"code","source":["accuracy_score(y_test.argmax(axis=1),predicted_classes_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WIPyDhEFjKVX","executionInfo":{"status":"ok","timestamp":1707898225466,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"f85631c4-d4d1-467b-9426-9f07faaa2992"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.96"]},"metadata":{},"execution_count":204}]},{"cell_type":"markdown","metadata":{"id":"mPtNaznhTYiz"},"source":["## Saving and Loading Models\n","\n","Now that we have a model trained, let's see how we can save and load it."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"7CzwVgKqTYi0","executionInfo":{"status":"ok","timestamp":1707898225812,"user_tz":-540,"elapsed":8,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"e3e16044-f434-4669-d042-90cc0f084b86"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["model.save('myfirstmodel.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"bxcdJr8YTYi0"},"outputs":[],"source":["from keras.models import load_model"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"YbPtGznaTYi0"},"outputs":[],"source":["newmodel = load_model('myfirstmodel.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0ltTSsZTYi0","executionInfo":{"status":"ok","timestamp":1707898226308,"user_tz":-540,"elapsed":501,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"228b72cc-0a83-439b-f9ea-3670779c12ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 6ms/step\n"]}],"source":["newprediction_X=newmodel.predict(scaled_X_test)"]},{"cell_type":"code","source":["np.argmax(newprediction_X, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axl5P4bjkl8f","executionInfo":{"status":"ok","timestamp":1707898226308,"user_tz":-540,"elapsed":22,"user":{"displayName":"조현욱","userId":"03838713573235288740"}},"outputId":"a34d0ef0-2afc-4ec9-f2a2-b0b446cebe09"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n","       0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n","       0, 1, 2, 2, 1, 2])"]},"metadata":{},"execution_count":209}]},{"cell_type":"markdown","metadata":{"id":"npluGXbfTYi0"},"source":["Great job! You now know how to preprocess data, train a neural network, and evaluate its classification performance!"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}